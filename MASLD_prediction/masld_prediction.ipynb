{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MASH Prediction By Logistic Regression\n",
    "Author: Nana K. Owusu\n",
    "\n",
    "Metabolic-dysfunction Associated Steatotic Liver Disease (MASLD) is a chronic liver disease with a mild form known as\n",
    "simple steatosis (macroscopic droplets of fat deposited in liver cells, MASLD) and a severe, progrossive form known as \n",
    "steatoshepatitis (inflammation and cellular injury in liver tissue, MASH). As the liver continues to store fat in its functional\n",
    "cells, a physiologic response leads to the deposition of fibrotic molecules in the extra-cellular matrix (fibrosis).\n",
    "Inflammation can also occur as a physiologic response to the stress, as well as cellular injury, where liver cells break\n",
    "apart due to excess fat deposition. In clinical practice, patients with fibrosis grade 2 along with histologic proof of\n",
    "inflammation and cellular injury are said to be at risk of irreversible damage to the liver (high-risk MASH). \n",
    "\n",
    "Magnetic resonance elastography (MRE) is the imaging technique that allows for non-invasive assesment of mechanical properties\n",
    "of biological tissue. This includes measures of elastic properties like storage modulus and shear stiffness as well as \n",
    "viscosity measures like loss modulus anby predictors of the logistic regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import import_module, reload\n",
    "from timeit import default_timer as timer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sys import path\n",
    "path.append('/Users/nowusu/GitHub_repos/ml_portfolio/MASLD_prediction/')\n",
    "\n",
    "import ml_lib\n",
    "# ml_lib = reload(ml_lib)\n",
    "from ml_lib import (roc_plot, classification_metrics, LOO_testing, calc_auc, DeLong2_test,\n",
    "                   final_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting and Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('/Users/nowusu/GitHub_repos/ml_portfolio/MASLD_prediction/NAFLD-four-cohorts_20220413.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SELECTING RELEVANT COLUMNS\n",
    "cols_3Dmre = ['Steatosis','Inflammation','Ballooning',\n",
    "              'NASH(0-1)','Fibrosis','PDFF',\n",
    "              'LS-3D-60','DR-3D-60','SM-3D-60', 'LM-3D-60']\n",
    "data=data[cols_3Dmre]\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "#ADDING TARGET COLUMNS\n",
    "# create categorcial column for fibrosis grade greater than 1\n",
    "data['Fib_gt1'] = data['Fibrosis'].apply(lambda x: int(x>1))\n",
    "\n",
    "# create categorical column for patients with high-risk MASH,\n",
    "# (HRM = MASH ^ Fib_gt1)\n",
    "data['HRM'] = data['NASH(0-1)'].astype('int16') & data['Fib_gt1']\n",
    "\n",
    "data.rename({'LS-3D-60':'SS','DR-3D-60':'DR',\n",
    "            'SM-3D-60':'SM','LM-3D-60':'LM',\n",
    "            'NASH(0-1)':'MASH_gt0'},axis=1, inplace=True)\n",
    "\n",
    "#RESETTING INDEX\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export cleaned data to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#SUMMARY\n",
    "print('\\nDATA TYPES:\\n-----------')\n",
    "print(data.dtypes)\n",
    "print('\\nMISSING VALUES:\\n---------------')\n",
    "print(data.isna().sum())\n",
    "print('\\nDIMENSIONS:\\n---------------')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning\n",
    "#### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINING GLOBAL ML PARAMETERS\n",
    "Cs = np.logspace(-4,4,9)\n",
    "cv = LeaveOneOut()\n",
    "scoring = 'accuracy'\n",
    "solver = 'liblinear'\n",
    "tol = 1e-6\n",
    "max_iter = int(1e6)\n",
    "class_weight = 'balanced'\n",
    "\n",
    "#DEFINING TARGETS\n",
    "# HRM is high-risk MASH a designation for those with positive MASH diagnosis by biopsy,\n",
    "# concomitant with fibrosis at stage 2 or above\n",
    "# MASH_gt0 is the positive diagnosis for metabolic dysfunction associated steatotic\n",
    "# liver disease via liver biopsy.\n",
    "targets = ['HRM']#,'MASH_gt0']\n",
    "\n",
    "#DEFINING MODELS\n",
    "models = {'SS':['SS'],\n",
    "          'FF':['PDFF'],\n",
    "          'SSFFDR':['SS','PDFF','DR']}\n",
    "\n",
    "#DEFINING METRICS DATAFRAME\n",
    "metric_cols=['target','model','AUC','AUC_L','AUC_U','TP','FP','TN','FN',\n",
    "             'sens','sens_L','sens_U','spec','spec_L','spec_U','NPV',\n",
    "             'NPV_L','NPV_U','PPV','PPV_L','PPV_U']\n",
    "metric_cols=metric_cols+[f\"MN_p_{model}\" for model in models.keys()]+[f\"DL_p_{model}\" for model in models.keys()]\n",
    "metrics=pd.DataFrame(columns=metric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrapped Training, Validation, and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TESTING PERFORMANCE OF EACH MODEL\n",
    "#Initialization\n",
    "alpha=0.05\n",
    "start = timer()\n",
    "#Looping Over Models and Targets\n",
    "for target in targets:\n",
    "    for model in models:\n",
    "        #Initializing Logistic Regression Model\n",
    "        clf=LogisticRegressionCV(Cs=Cs,cv=cv,scoring=scoring,solver=solver, \\\n",
    "                                 tol=tol,max_iter=max_iter,class_weight=class_weight)\n",
    "        \n",
    "        #Defining Features and Target\n",
    "        X=data[models[model]]\n",
    "        Y=data[target]\n",
    "        \n",
    "        #Defining Output Columns\n",
    "        data[target+'_'+model+'_proba']=np.nan\n",
    "        data[target+'_'+model+'_pred']=np.nan\n",
    "        \n",
    "        #Computing Test Predictions With Bootstrap\n",
    "        LOO_testing(data, target, model, X, Y, clf)\n",
    "        \n",
    "        #Test AUC\n",
    "        AUC_L, AUC, AUC_U = calc_auc(data, Y, data[target+'_'+model+'_proba'], alpha)\n",
    "        \n",
    "        #Test Classification Metrics\n",
    "        cmatrix_dict = classification_metrics(data, Y, data[target+'_'+model+'_pred'], \n",
    "                                              alpha)\n",
    "        \n",
    "        #Storing Results\n",
    "        new_row={'target':target,'model':model,\n",
    "                 'AUC':AUC,'AUC_L':AUC_L,'AUC_U':AUC_U}\n",
    "        new_row.update(cmatrix_dict)\n",
    "        metrics = pd.concat([metrics, pd.DataFrame([new_row])], ignore_index=True)\n",
    "        \n",
    "end = timer()\n",
    "\n",
    "mins, secs = divmod(end - start, 60)\n",
    "hrs, mins = divmod(mins, 60)\n",
    "print(f'elapsed time: {hrs} hr {mins} min {round(secs, 2)} sec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "#### Exact McNemar Test of Sensitivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model1 in models:\n",
    "    k=0\n",
    "    for target in targets:\n",
    "        for model2 in models:\n",
    "            #Labeling Positive Cohort Predictions Correct/Incorrect\n",
    "            TP1=data[target+'_'+model1+'_pred'][data[target]==1]\n",
    "            TP2=data[target+'_'+model2+'_pred'][data[target]==1]\n",
    "            ctable=np.array([[((TP1==1)&(TP2==1)).sum(),((TP1==1)&(TP2==0)).sum()],\\\n",
    "                             [((TP1==0)&(TP2==1)).sum(),((TP1==0)&(TP2==0)).sum()]])\n",
    "            \n",
    "            #Different Models\n",
    "            if model1!=model2:\n",
    "                metrics.loc[k,'MN_p_'+model1]=mcnemar(ctable,exact=True).pvalue\n",
    "            \n",
    "            #Same Model\n",
    "            else:\n",
    "                metrics.loc[k,'MN_p_'+model1]=np.nan\n",
    "            \n",
    "            #Row Iterator\n",
    "            k+=1\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delong Test of AUCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model1 in models:\n",
    "    k=0\n",
    "    for target in targets:\n",
    "        for model2 in models:\n",
    "            #Different Models\n",
    "            if model1!=model2:\n",
    "                X1=np.array((data[target+'_'+model1+'_proba'])[data[target]==1])\n",
    "                Y1=np.array((data[target+'_'+model1+'_proba'])[data[target]==0])\n",
    "                X2=np.array((data[target+'_'+model2+'_proba'])[data[target]==1])\n",
    "                Y2=np.array((data[target+'_'+model2+'_proba'])[data[target]==0])\n",
    "                metrics.loc[k,'DL_p_'+model1] = DeLong2_test(X1,Y1,X2,Y2)[1]\n",
    "                \n",
    "            #Same Model\n",
    "            else:\n",
    "                metrics.loc[k,'DL_p_'+model1]=np.nan\n",
    "                \n",
    "            #Row Iterator\n",
    "            k+=1\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrm_fig = plt.figure(figsize=(10,10))\n",
    "hrm_fig.add_subplot()\n",
    "roc_plot(hrm_fig, data, 'HRM', ['SS','FF','SSFFDR'], 'Predicting High-Risk MASH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INITIALIZATION\n",
    "clfs={target:{model:LogisticRegressionCV(Cs=Cs,cv=cv,scoring=scoring,solver=solver,tol=tol,max_iter=max_iter,\n",
    "                                         class_weight=class_weight) for model in models} for target in targets}\n",
    "\n",
    "model_keys = {'SS':['SS'],'FF':['FF'],\n",
    "              'SSFFDR':['SS','FF','DR']}\n",
    "\n",
    "final_cols=['target','model','AUC','intercept',\n",
    "            'beta_SS','beta_DR','beta_FF',\n",
    "            'beta_std_SS','beta_std_DR','beta_std_FF',\n",
    "            'OR_std_SS','OR_std_DR','OR_std_FF']\n",
    "final=pd.DataFrame(columns=final_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINAL TRAINING\n",
    "# cutoffs=np.linspace(1,0,1001)\n",
    "# k=0\n",
    "# for target in targets:\n",
    "#     for model in models:\n",
    "#         final.loc[k,'target']=target\n",
    "#         final.loc[k,'model']=model\n",
    "        \n",
    "#         #Cross Validated Training\n",
    "#         X=data[models[model]]\n",
    "#         Y=data[target]\n",
    "#         clfs[target][model].fit(X,Y)\n",
    "        \n",
    "#         #Checking AUC\n",
    "#         Y_proba=clfs[target][model].predict_proba(X)[:,1]\n",
    "        \n",
    "#         #Computing AUC\n",
    "#         final.loc[k,'AUC']=roc_auc_score(Y,Y_proba)\n",
    "        \n",
    "#         #Getting Intercept\n",
    "#         final.loc[k,'intercept']=clfs[target][model].intercept_[0]\n",
    "        \n",
    "#         #Getting Coefficients\n",
    "#         coefs=clfs[target][model].coef_[0]\n",
    "#         for i,coef in enumerate(coefs):\n",
    "#             final.loc[k,f'beta_{model_keys[model][i]}']=coef\n",
    "#             final.loc[k,f'beta_std_{model_keys[model][i]}']=\\\n",
    "#             final.loc[k,f'beta_{model_keys[model][i]}']*(X[models[model][i]].std())\n",
    "#             final.loc[k,f'OR_std_{model_keys[model][i]}']=\\\n",
    "#             np.exp(final.loc[k,f'beta_std_{model_keys[model][i]}'])\n",
    "        \n",
    "#         #Saving Model\n",
    "# #         dump(clfs[target][model], f'3_cohorts/LRM_Fib_{target}_{model}.joblib')\n",
    "# #         dump(clfs[target][model], f'4_cohorts/LRM_Fib_{target}_{model}.joblib')\n",
    "# #         dump(clfs[target][model], f'nash/LRM_{target}_{model}.joblib')\n",
    "        \n",
    "#         #Row Iterator\n",
    "#         k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training(data, final, ['HRM'], ['SS','FF','DR'], model_keys, clfs)\n",
    "final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
